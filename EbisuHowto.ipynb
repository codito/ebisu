{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ebisu howto\n",
    "A quick introduction to using the library to schedule spaced-repetition quizzes in a principled, probabilistically-grounded, Bayesian manner.\n",
    "\n",
    "See https://fasiha.github.io/ebisu/ for details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebisu\n",
    "\n",
    "defaultModel = (4., 4., 24.) # alpha, beta, and half-life in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebisu—this is what we’re here to learn about!\n",
    "\n",
    "Ebisu is a library that’s expected to be embedded inside quiz apps, to help schedule quizzes intelligently. It uses Bayesian statistics to let the app predict what the recall probability is for any fact that the student has learned, and to update that prediction based onthe results of a quiz.\n",
    "\n",
    "Ebisu uses three numbers to describe its belief about the time-evolution of each fact’s recall probability. Its API consumes them as a 3-tuple, and they are:\n",
    "\n",
    "- the first we call “alpha” and must be ≥ 2 (well, technically, ≥1 is the raw minimum but unless you’re a professor of statistics, keep it more than two);\n",
    "- the second is “beta” and also must be ≥ 2. These two numbers encode our belief about the distribution of recall probabilities at\n",
    "- the third element, which here is a half-life. This has units of time, and for this example, we’ll assume it’s in hours. It can be any positive float, but we choose the nice round number of 24 hours.\n",
    "\n",
    "For the nerds: alpha and beta parameterize a Beta distribution to describe our prior belief of the recall probability one half-life (one day) after a fact’s most recent quiz.\n",
    "\n",
    "For the rest of us: these three numbers mean we expect the recall probability for a newly-learned fact to be 50% after one day, but allow uncertainty: the recall probability after a day is “around” 42% to 58% (±1 standard deviation).\n",
    "\n",
    "---\n",
    "\n",
    "Now. Let’s create a mock database of facts. Say a student has learned two facts, one on the 19th at 2200 hours and another the next morning at 0900 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "date0 = datetime(2017, 4, 19, 22, 0, 0)\n",
    "\n",
    "database = [dict(factID=1, model=defaultModel, lastTest=date0),\n",
    "            dict(factID=2, model=defaultModel, lastTest=date0 + timedelta(hours=11))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning the second fact, at 0900, what does Ebisu expect each fact’s probability of recall to be, for each of the facts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2017-04-20 09:06:00,\n",
      "Fact #1 probability of recall: 71.5%\n",
      "Fact #2 probability of recall: 99.7%\n"
     ]
    }
   ],
   "source": [
    "oneHour = timedelta(hours=1)\n",
    "\n",
    "now = date0 + timedelta(hours=11.1)\n",
    "print(\"On {},\".format(now))\n",
    "for row in database:\n",
    "    recall = ebisu.predictRecall(row['model'],\n",
    "                                 (now - row['lastTest']) / oneHour,\n",
    "                                 exact=True)\n",
    "    print(\"Fact #{} probability of recall: {:0.1f}%\".format(row['factID'], recall * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both facts are expected to still be firmly in memory—especially the second one since it was just learned! So the quiz app doesn’t ask the student to review anything yet—though if she wanted to, the quiz app would pick the fact most in danger of being forgotten.\n",
    "\n",
    "Note how we used `ebisu.predictRecall`, which accepts\n",
    "- the current model, and\n",
    "- the time elapsed since this fact’s last quiz,\n",
    "\n",
    "and returns a `float`.\n",
    "\n",
    "…\n",
    "\n",
    "Now a few hours have elapsed. It’s just past midnight on the 21st and the student opens the quiz app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2017-04-21 00:30:00,\n",
      "Fact #1 probability of recall: 46.8%\n",
      "Fact #2 probability of recall: 63.0%\n"
     ]
    }
   ],
   "source": [
    "now = date0 + timedelta(hours=26.5)\n",
    "print(\"On {},\".format(now))\n",
    "for row in database:\n",
    "    recall = ebisu.predictRecall(row['model'],\n",
    "                                 (now - row['lastTest']) / oneHour,\n",
    "                                 exact=True)\n",
    "    print(\"Fact #{} probability of recall: {:0.1f}%\".format(row['factID'], recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the quiz app has been configured to quiz the student if the expected recall probability drops below 50%—which it did for fact 1! The app shows the flashcard once, analyzes the user's response, and sets the result of the quiz to `1` if passed and `0` if failed. It calls Ebisu to update the model, giving it this result as well as the `total` number of times it showed this flashcard (one time—Ebisu can support more advanced cases where an app reviews the same flashcard multiple times in a single review session, but let's keep it simple for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model for fact #1: (4.040794974809565, 4.040794974809568, 29.18373827290736)\n"
     ]
    }
   ],
   "source": [
    "row = database[0] # review FIRST question\n",
    "\n",
    "result = 1 # success!\n",
    "total = 1 # number of times this flashcard was shown (fixed)\n",
    "newModel = ebisu.updateRecall(row['model'],\n",
    "                              result,\n",
    "                              total,\n",
    "                              (now - row['lastTest']) / oneHour)\n",
    "print('New model for fact #1:', newModel)\n",
    "row['model'] = newModel\n",
    "row['lastTest'] = now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how `ebisu.updateRecall` takes\n",
    "- the current model,\n",
    "- the quiz result, and\n",
    "- the time elapsed since the last quiz,\n",
    "\n",
    "and returns a new model (the new 3-tuple of “alpha”, “beta” and time). We put the new model and the current timestamp into the database.\n",
    "\n",
    "Now. Suppose the student asks to review another fact—fact 2. It was learned just earlier that morning, and its recall probability is expected to be around 63%, but suppose the student fails this quiz, as sometimes happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model for fact #2: (4.958645489170429, 4.9586454891705465, 19.76772867641237)\n"
     ]
    }
   ],
   "source": [
    "row = database[1] # review SECOND question\n",
    "\n",
    "result = 0\n",
    "newModel = ebisu.updateRecall(row['model'],\n",
    "                              result,\n",
    "                              total,\n",
    "                              (now - row['lastTest']) / oneHour)\n",
    "print('New model for fact #2:', newModel)\n",
    "row['model'] = newModel\n",
    "row['lastTest'] = now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new parameters for this fact differ from the previous one because (1) the student failed this quiz while she passed the other, (2) different amounts of time had elapsed since the respective facts were last seen.\n",
    "\n",
    "Ebisu provides a method to convert parameters to “expected half-life”. It is *not* an essential feature of the API but can be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact #1 has half-life of ≈29.2 hours\n",
      "Fact #2 has half-life of ≈19.8 hours\n"
     ]
    }
   ],
   "source": [
    "for row in database:\n",
    "    meanHalflife = ebisu.modelToPercentileDecay(row['model'])\n",
    "    print(\"Fact #{} has half-life of ≈{:0.1f} hours\".format(row['factID'], meanHalflife))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the half-life (the time between quizzes for expected recall probability to drop to 50%) for the first question increased from 24 to 29 hours after the student got it right, while it decreased to 20 hours for the second when she got it wrong. Ebisu has incorporated the fact that the second fact had been learned not that long ago and should have been strong, and uses the surprising quiz result to strongly adjust its belief about its recall probability.\n",
    "\n",
    "---\n",
    "\n",
    "Suppose the user is tired of reviewing the first fact so often because it’s something they know very well. You could allow the user to delete this flashcard, add it again with a longer initial halflife. But Ebisu gives you a function that will explicitly rescale the halflife of the card as is: `ebisu.rescaleHalflife`, which takes a positive number to act as the halflife scale. In this case, the new halflife is *two* times the old halflife."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact #1 has half-life of ≈58.4 hours\n",
      "Fact #2 has half-life of ≈19.8 hours\n"
     ]
    }
   ],
   "source": [
    "database[0]['model'] = ebisu.rescaleHalflife(database[0]['model'], 2.0)\n",
    "\n",
    "for row in database:\n",
    "    meanHalflife = ebisu.modelToPercentileDecay(row['model'])\n",
    "    print(\"Fact #{} has half-life of ≈{:0.1f} hours\".format(row['factID'], meanHalflife))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user was worried that this flashcard was shown too *infrequently*, and wanted to see it three times as often, you might pass in `1/3` as the second argument.\n",
    "\n",
    "This short notebook shows the major functions in the Ebisu API:\n",
    "- `ebisu.predictRecall` to find out the expected recall probability for a fact right now, and\n",
    "- `ebisu.updateRecall` to update those expectations when a new quiz result is available.\n",
    "- `ebisu.modelToPercentileDecay` to find the time when the recall probability reaches a certain value.\n",
    "- `ebisu.rescaleHalflife` to adjust the halflife up and down without a quiz.\n",
    "\n",
    "For more advanced functionality, including non-binary fuzzy quizzes, do consult the [Ebisu](https://fasiha.github.io/ebisu/) website, which links to the API’s docstrings and explains how this all works in greater detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adanced topics\n",
    "### Speeding up `predictRecall`\n",
    "\n",
    "Above, we used `predictRecall` with the `exact=True` keyword argument to have it return true probabilities. We can reduce runtime if we use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.17 µs ± 430 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "4.45 µs ± 110 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# As above: a bit slow to get exact probabilities\n",
    "%timeit ebisu.predictRecall(database[0]['model'], 100., exact=True)\n",
    "\n",
    "# A bit faster alternative: get log-probabilities (this is the defalt)\n",
    "%timeit ebisu.predictRecall(database[0]['model'], 100., exact=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
